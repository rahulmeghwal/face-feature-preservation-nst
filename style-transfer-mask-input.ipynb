{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNrUhDEGKzTVmKbSCe/sGwD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"iplPbyvtsYdb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671135168938,"user_tz":300,"elapsed":18240,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}},"outputId":"1e624551-559d-4260-ed78-c2921243ad18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/cv_project_fall_2022')"],"metadata":{"id":"CZQpAQ7Wt1B4","executionInfo":{"status":"ok","timestamp":1671135168938,"user_tz":300,"elapsed":4,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import DataLoader\n","\n","import utils.utils as utils\n","from models.definitions.transformer_net_new import TransformerNet\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from torchvision import transforms"],"metadata":{"id":"HBabeISmtEhw","executionInfo":{"status":"ok","timestamp":1671135177150,"user_tz":300,"elapsed":8215,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def stylize_static_image(inference_config):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Prepare the model - load the weights and put the model into evaluation mode\n","    stylization_model = TransformerNet().to(device)\n","    model_saved_path = inference_config['model_saved_path']\n","    training_state = torch.load(model_saved_path)\n","    state_dict = training_state[\"state_dict\"]\n","    stylization_model.load_state_dict(state_dict, strict=True)\n","    stylization_model.eval()\n","\n","    if inference_config['verbose']:\n","        utils.print_model_metadata(training_state)\n","\n","    content_img_path = inference_config['content_images_path']\n","    print(content_img_path)\n","    content_image_to_show = Image.open(content_img_path)\n","    plt.imshow(content_image_to_show)\n","    plt.show()\n","\n","    \n","\n","    with torch.no_grad():\n","        transform_list = [transforms.ToTensor()]\n","        transform = transforms.Compose(transform_list)\n","        \n","        target_transform_list = [transforms.ToTensor()]\n","        #target_transform_list = [transforms.ToTensor(), transforms.GaussianBlur(kernel_size=(51, 51), sigma=(70, 70))]\n","        transform_target = transforms.Compose(target_transform_list)\n","        \n","        img = utils.load_image(content_img_path, target_shape=inference_config['img_width'])\n","        img = transform(img).to(device)\n","\n","        face_masked_image_batch = utils.load_image(inference_config['content_images_mask_path'], target_shape=inference_config['img_width'], RGB=False)\n","        face_masked_image_batch = transform_target(face_masked_image_batch).to(device)\n","        face_masked_image_batch = face_masked_image_batch * 0.03\n","\n","        result = torch.cat([img, face_masked_image_batch], dim=0)\n","\n","        print(' Infering...')\n","        print(img.shape)\n","        content_image = result.repeat(1, 1, 1, 1)\n","        print(content_image.shape)\n","        print(' Infering Ends...')\n","        stylized_img = stylization_model(content_image).to('cpu').numpy()[0]\n","        utils.save_and_maybe_display_image(inference_config, stylized_img, should_display=inference_config['display'])\n"],"metadata":{"id":"LYGOAz1ItWAM","executionInfo":{"status":"ok","timestamp":1671135177151,"user_tz":300,"elapsed":5,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["inference_config = dict()\n","\n","# Content image(s) to stylize\n","inference_config['content_input'] = 'lion.jpg'\n","# Resize content image to this width\n","inference_config['img_width'] = 500\n","# Set to True to print Model Information\n","inference_config['verbose'] = True\n","# Display Result \n","inference_config['display'] = True\n","# Output Images Path \n","inference_config['redirected_output'] = os.path.join('/content/drive/MyDrive/cv_project_fall_2022', 'data', 'output-images')\n","\n","\n","# 1st conv layer\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_content_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","# 3rd conv layer\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_content_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","# 1st conv layer\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_1st_layer_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","# 2nd conv layer\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_1st_layer_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","# 2nd conv layer - using content and style loss of layer 2\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/ckpt_style_face_layer_2_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_depth_face_edge_layer_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_0_batch_1399.pth'\n","\n","# Depth and Face Edge - Final\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_depth_face_edge_layer_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","# Face Edge Only Mosaic\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_face_edge_only_new_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_6_batch_1899.pth'\n","\n","# Face Edge Only - Final\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_face_edge_only_ldc_pre_mask_new_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","\n","# Test \n","#inference_config['model_saved_path'] = model_binaries_path\n","inference_config['model_saved_path'] = \"/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/blurred_ckpt_style_face_layer_1_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_0_batch_1699.pth\"\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/blurred_ckpt_style_face_layer_1_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_499.pth'\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_face_layer_2_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","#inference_config['model_saved_path'] = \"/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_3rd_layer_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth\"\n","\n","\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","\n","\n","\n","'''Mosaic'''\n","# Style Image Path\n","inference_config['style_images_path'] = '/content/drive/MyDrive/cv_project_fall_2022/data/style-images/mosaic.jpg'\n","# [DONE] Style Transfer on Face using blurred Style Image + Edge Loss\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/blurred_ckpt_style_face_layer_1_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_3_batch_1899.pth'\n","# Saving checkpoint :  /content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/blurred_ckpt_style_face_layer_1_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth\n","# [TODO] Edge Loss\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/mosaic/ckpt_style_face_edge_only_new_mosaic_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","# [TODO]  Content Preserve + Content Style Transfer on Face\n","\n","'''Edtaonist'''\n","inference_config['style_images_path'] = '/content/drive/MyDrive/cv_project_fall_2022/data/style-images/edtaonisl.jpg'\n","# [DONE] Style Transfer on Face using blurred Style Image + Edge Loss\n","inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl-blurred-style-image-mask_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","\n","# [DONE] Style Transfer on Face using blurred Style Image + Edge Loss\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl-blurred-style-image-mask_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","# [TODO] Edge Loss\n","# [TODO] Content Preserve + Content Style Transfer on Face\n","#inference_config['model_saved_path'] = '/content/drive/MyDrive/cv_project_fall_2022/models/checkpoints/edtaonisl/ckpt_style_face_content_edtaonisl_cw_1.0_sw_400000.0_tw_0_epoch_9_batch_1899.pth'\n","\n","\n","\n","os.makedirs(inference_config['redirected_output'], exist_ok=True)\n","test_images_path = '/content/drive/MyDrive/cv_project_fall_2022/face_mask/test_images/'\n","all_test_images = os.listdir(test_images_path)\n","\n","\n","def get_mask_path(file_path):\n","    file_name = file_path.split('/')[-1]\n","    file_name_split = file_name.split('_')\n","    if(file_name_split[1] == 'Election'):\n","        file_name_split[1] = 'Election_Campain'\n","    if(file_name_split[1] == 'Press'):\n","        file_name_split[1] = 'Press_Conference'\n","    \n","    \n","\n","    dir_name = file_name_split[0] + '--' + file_name_split[1]\n","    return file_path.replace(\"/test_images/\", \"/data/widerface/WIDER_train/masks/\" + dir_name + \"/\")\n","\n","# Show style Image\n","style_image_path = inference_config['style_images_path']\n","style_image_to_show = Image.open(style_image_path)\n","plt.imshow(style_image_to_show)\n","plt.show()\n","\n","for test_image in all_test_images:\n","    inference_config['content_images_path'] = test_images_path + test_image\n","    inference_config['content_images_mask_path'] = get_mask_path(inference_config['content_images_path'])\n","    stylize_static_image(inference_config)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1jsj8N5ZPsV4OsCJN-T4gZZQAz2F0eXzP"},"id":"h23_r4lCuOgJ","executionInfo":{"status":"ok","timestamp":1671135720909,"user_tz":300,"elapsed":15564,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}},"outputId":"e6d5b103-4625-44b0-c56d-b99e30d74431"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"hZ83QOsqLZze","executionInfo":{"status":"aborted","timestamp":1671081208284,"user_tz":300,"elapsed":2,"user":{"displayName":"Rahul Meghwal","userId":"07649752308203231636"}}},"execution_count":null,"outputs":[]}]}